{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: This is a notebook to acquire and transform the raw Amazon sales rank source data into a useable dataframe. The raw data has not been included in the github repo because it is too large (7.82 GB). As a result, the code below has not been amended to pull from a non-local source. The dataframe generated by parsing and aggregating the raw data has been saved as a csv in this notebook. \n",
    "\n",
    "The raw data is available here: \n",
    "https://www.kaggle.com/ucffool/amazon-sales-rank-data-for-print-and-kindle-books#ranks.zip\n",
    "\n",
    "In order to reproduce code below, please follow instructions:\n",
    "- normpath - can be replaced by the extracted \"ranks_norm folder\" in kaggle source data\n",
    "- outpath - can be replaced by 'https://github.com/jitsen-design/Data-607-Final-Project/tree/master/'\n",
    "- mainpath and meta - can be replaced by the \"amazon_com_extras.csv\" in kaggle source data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile \n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract \"ranks norm\" folder\n",
    " \n",
    "#thezipfile = '/Users/euniceok/PycharmProjects/cuny/spring2019/Final Project/amazon-sales-rank-data-for-print-and-kindle-books/ranks_norm.zip'\n",
    "#targetdir = '/Users/euniceok/PycharmProjects/cuny/spring2019/Final Project/amazon-sales-rank-data-for-print-and-kindle-books/'\n",
    "\n",
    "#with zipfile.ZipFile(thezipfile,'r') as zip_ref: zip_ref.extractall(targetdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract \"ranks\" folder\n",
    "\n",
    "#seczipfile = '/Users/euniceok/PycharmProjects/cuny/spring2019/Final Project/amazon-sales-rank-data-for-print-and-kindle-books/ranks.zip'\n",
    "#with zipfile.ZipFile(seczipfile,'r') as zip_ref: zip_ref.extractall(targetdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse json for just one book file sample\n",
    "normpath = '/Users/euniceok/PycharmProjects/cuny/spring2019/Final Project/amazon_data/ranks_norm/'\n",
    "filename = '000721393X_com_norm.json'\n",
    "#filename = 'B00WPFOVS0_com_norm.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1501005600', 956170)\n"
     ]
    }
   ],
   "source": [
    "# open up the json file\n",
    "with open(normpath+filename) as f:\n",
    "    d = json.load(f)\n",
    "    print(next(iter(d.items()))) # print first key: value pair just to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all files in the normed rankings folder\n",
    "filenames = []\n",
    "for it in os.listdir(normpath):\n",
    "    if it.endswith(\".json\"):\n",
    "        filenames.append(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66760"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many files (books) there are\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/euniceok/PycharmProjects/cuny/spring2019/Final Project/amazon-sales-rank-data-for-print-and-kindle-books/ranks_norm/B00BFSMXB0_com_norm.json'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normpath+filenames[:1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2 ms ± 809 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for file in filenames[:10]: \n",
    "    with open(normpath+file) as f:\n",
    "        file = file.split(\"_\")[0]\n",
    "        d = json.load(f)\n",
    "        if d == []:\n",
    "            continue\n",
    "        else:\n",
    "            val_max = max(d.values())\n",
    "            val_min = min(d.values())\n",
    "            new_dict.update({file: (val_max, val_min)})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 ms ± 10.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for file in filenames[:100]: \n",
    "    with open(normpath+file) as f:\n",
    "        file = file.split(\"_\")[0]\n",
    "        d = json.load(f)\n",
    "        if d == []:\n",
    "            continue\n",
    "        else:\n",
    "            val_max = max(d.values())\n",
    "            val_min = min(d.values())\n",
    "            new_dict.update({file: (val_max, val_min)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 43s ± 4.93 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for file in filenames: \n",
    "    with open(normpath+file, errors='replace') as f:\n",
    "        file = file.split(\"_\")[0]\n",
    "        d = json.load(f)\n",
    "        if d == []:\n",
    "            continue\n",
    "        else:\n",
    "            val_max = max(d.values())\n",
    "            val_min = min(d.values())\n",
    "            new_dict.update({file: (val_max, val_min)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_rank</th>\n",
       "      <th>min_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00BFSMXB0</th>\n",
       "      <td>2699752</td>\n",
       "      <td>227614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B07CKYQ1MV</th>\n",
       "      <td>39185</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B06XV6XP2G</th>\n",
       "      <td>355931</td>\n",
       "      <td>35857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609454839</th>\n",
       "      <td>1872441</td>\n",
       "      <td>39881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178133188X</th>\n",
       "      <td>823407</td>\n",
       "      <td>14391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            max_rank  min_rank\n",
       "B00BFSMXB0   2699752    227614\n",
       "B07CKYQ1MV     39185      1067\n",
       "B06XV6XP2G    355931     35857\n",
       "1609454839   1872441     39881\n",
       "178133188X    823407     14391"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from dict to dataframe \n",
    "asrdf = pd.DataFrame.from_dict(new_dict,orient='index')\n",
    "asrdf = asrdf.rename(columns={0: \"max_rank\", 1:\"min_rank\"}) \n",
    "asrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66753, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asrdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = '/Users/euniceok/PycharmProjects/cuny/spring2019/Final Project/amazon-sales-rank-data-for-print-and-kindle-books/output'\n",
    "# asrdf.to_csv(outpath + '/min_maxranks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ASIN  max_rank  min_rank\n",
      "0  B00BFSMXB0   2699752    227614\n",
      "1  B07CKYQ1MV     39185      1067\n",
      "2  B06XV6XP2G    355931     35857\n",
      "3  1609454839   1872441     39881\n",
      "4  178133188X    823407     14391\n",
      "         ASIN GROUP     FORMAT  \\\n",
      "0  1250150183  book  hardcover   \n",
      "1   778319997  book  hardcover   \n",
      "2  1608322564  book  hardcover   \n",
      "3   310325331  book  hardcover   \n",
      "4   312616295  book  hardcover   \n",
      "\n",
      "                                               TITLE  \\\n",
      "0  The Swamp: Washington's Murky Pool of Corrupti...   \n",
      "1            Rise and Shine, Benedict Stone: A Novel   \n",
      "2  Sell or Be Sold: How to Get Your Way in Busine...   \n",
      "3  Christian Apologetics: An Anthology of Primary...   \n",
      "4  Gravity: How the Weakest Force in the Universe...   \n",
      "\n",
      "                               AUTHOR                   PUBLISHER  \n",
      "0                        Eric Bolling          St. Martin's Press  \n",
      "1                     Phaedra Patrick              Park Row Books  \n",
      "2                       Grant Cardone  Greenleaf Book Group Press  \n",
      "3  Khaldoun A. Sweis, Chad V. Meister                   Zondervan  \n",
      "4                         Brian Clegg          St. Martin's Press  \n"
     ]
    }
   ],
   "source": [
    "# create df with isbn, min sales rank, max sales rank, metadata\n",
    "\n",
    "# pull in min/max ranks\n",
    "amdf = pd.read_csv(outpath + '/min_maxranks.csv').rename(columns={'Unnamed: 0':'ASIN'})\n",
    "print(amdf.head(5))\n",
    "\n",
    "# pull in metadata\n",
    "mainpath = '/Users/euniceok/PycharmProjects/cuny/spring2019/Final Project/amazon-sales-rank-data-for-print-and-kindle-books'\n",
    "meta = '/amazon_com_extras.csv'\n",
    "metadf = pd.read_csv(mainpath + meta, encoding='ISO-8859-1').drop(columns='Unnamed: 6')\n",
    "print(metadf.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66753, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63748, 6)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.merge(amdf, metadf, on='ASIN', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.sort_values('min_rank', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv(outpath + '/masterrankings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51898, 8)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
